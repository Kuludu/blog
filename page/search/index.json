[{"content":"深信服作为全国各大高校主流的VPN提供商，却魔改VPN协议，甚至会向系统加入自签名的CA证书（具体的危害可以搜素之）。本文介绍一种将深信服VPN客户端EasyConnect放进容器里的方法，实现应用与宿主机隔离，仅向外部暴露代理接口，实现净化的同时允许按需连接（以江南大学作为案例）。\n本文默认docker已经完成安装。\n部署docker-easyconnect容器 这一步主要需要参考docker-easyconnect项目的说明文档。需要注意的是目前大部分高校所使用的EasyConnect版本应该是具有图形界面的版本，所以需要选择第二个版本。同时可以考虑去掉官方文档中的：\nti：用于启动一个交互式终端，意义不大。 rm：在容器停止后删除容器，可以考虑保留容器下次直接重新启动。 另外端口可以按照实际情况进行修改，比如8888端口一般会和jupyter冲突。如果你和我一样使用的是macOS系统，可以使用Screen Sharing.app连接VNC而不需要下载新的软件。\n增加Clash规则 按照官方文档中的步骤，此时系统已经在1080端口启动了一个socks5代理，在8888端口启动了一个http代理。我们现在需要做的就是修改系统代理，让流量走我们刚刚部署好的净化容器。\n这里我们使用Clash作为我们的代理软件。具体可以添加以下规则：\n1 2 3 4 5 6 7 8 9 10 # 放通VPN及内网认证 - DOMAIN,vpn.jiangnan.edu.cn,DIRECT - DOMAIN,net.jiangnan.edu.cn,DIRECT - IP-CIDR,202.195.159.160/32,DIRECT # 江南大学网站群 - DOMAIN-SUFFIX,jiangnan.edu.cn,VPN # 江南大学内网IP段 - IP-CIDR,172.16.0.0/12,VPN # 江南大学外网IP段 - IP-CIDR,202.192.0.0/12,VPN 除了vpn.jiangnan.edu.cn和net.jiangnan.edu.cn这两个基础性域名需要直连以外，还需要放通202.195.159.160这个IP，这是在短信认证阶段抓包发现的，似乎是用作EasyConnect登陆验证的。\n包含端口设置和代理设置的配置文件可以参考：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 mixed-port: 7890 allow-lan: false mode: Rule log-level: info external-controller: 127.0.0.1:9090 proxies: - {name: VPN-socks5, server: localhost, port: 1080, type: socks5} proxy-groups: - name: VPN type: select proxies: - VPN-socks5 - DIRECT rules: - DOMAIN,vpn.jiangnan.edu.cn,DIRECT - DOMAIN,net.jiangnan.edu.cn,DIRECT - IP-CIDR,202.195.159.160/32,DIRECT - DOMAIN-SUFFIX,jiangnan.edu.cn,VPN - IP-CIDR,172.16.0.0/12,VPN - IP-CIDR,202.192.0.0/12,VPN 如果你不需要直连内网IP，也可以不用加入内网和外网IP段。\nNote：若你需要为你的学校配置规则，可以参考以下思路：\n替换学校网站群域名，尤其注意不能被代理的域名（比如VPN登陆和内网登陆系统等，可以观察Clash日志）。 获取学校内网网段，这个信息一般是不公开的，可以在不冲突的情况下设置大一些，替换内网段。 通过IP获取学校外网ASN，可以使用https://tools.ipip.net/as.php，替换外网段。 详细的配置文件说明这里不再赘述，可以参考Clash Wiki的说明。\n为SSH添加ProxyCommand 到目前为止常规的代理配置基本上就结束了。但是对于计算机专业而言，可能还有通过SSH连接内网服务器的需求。由于SSH默认是不支持socks5或http代理的，我们还需要进一步配置。\n配置的方法其实也很简单，在ProxyCommand中使用netcat设置SSH的代理即可，可以参考以下配置（~/.ssh/config）：\n1 2 3 4 Host host-1 HostName 172.xx.xx.xx User xxxx ProxyCommand nc -x 127.0.0.1:7890 -X 5 %h %p 如果不想写配置文件也可以在SSH连接时加上，比如：\n1 ssh -o \u0026#34;ProxyCommand=nc -x 127.0.0.1:7891 -X 5 %h %p\u0026#34; xxxx@172.xx.xx.xx 值得注意的是，netcat在不同操作系统上的实现并不相同，这里的实验环境是macOS，如果是Windows WSL或者其他Linux发行版，可能需要修改对应的nc命令参数。\nReference docker-easyconnect Clash Wiki ","date":"2025-05-08T15:50:00+08:00","permalink":"https://blog.kuludu.net/article/easyconnect-purify-jnu-as-example/","title":"EasyConnect净化-以江南大学为例"},{"content":"最近在进行学位论文的撰写工作的过程中遇到了这样一系列的问题：\n按照学校论文格式要求，章节标题应当使用中文汉字，而小节标题应当使用阿拉伯数字。即如以下形式：\n第一章 绪论\n1.1 研究背景及意义\n1.2 国内外研究进展\n但是这样的编号要求会导致章节与小节编码符号不统一，最后显示为一.1研究背景及意义。不过解决这个问题的方法很简单，只需要在多级列表里选择正规形式编号即可。\n但是这样操作还会引起另一个问题，那就是图表标题的按章自动编号也变成了图 一.1或表 一.1。\n参考资料[1]的做法，我们可以将章节编号的域代码修改为{ QUOTE \u0026quot;一九一一年一月{ STYLEREF 1 \\s }日\u0026quot; \\@\u0026quot;D\u0026quot; }实现阿拉伯数字的自动编号。但是，这一点在macOS下的MS Office里不能直接实现，原因是域代码中的{}符号是不能直接打出来的，必须使用快捷键生成。这就很尴尬了，因为macOS的快捷键和Windows的压根对不上。\n当然这里是存在快捷键的，具体可以参考资料[2]。不过本文想提供一种不用快捷键的实现方法，包括Windows其实也可以这么做。\n解决步骤 和[1]中标准步骤一样，先对图表进行插入题注的操作，然后切换章节部分的域代码。 在插入\u0026gt;域选项里随便添加一个域代码，比如AUTONUM（位置参考图1，Windows版在文档部件里面）。 对插入的域代码再次进行切换域代码的操作，这样就生成了一个{}。 然后按照 [1]中的步骤对应修改域代码即可。 当然我们不可能每次插入图表都这样操作一次，同样我们不使用快捷键也可以添加文档基块。\n光标选择图或表的编号。 在自动图文集\u0026gt;新建添加（位置参考图2，Windows版同样在文档部件里）。 随便取一个名字，比如图，然后在想插入的位置输入对应图文集的名字就可以快捷插入编号了。 macOS的MS Office真的是个半成品\u0026hellip;\nReference\nhttps://yxchangingself.xyz/posts/2028856356/ https://support.microsoft.com/zh-cn/office/word-%E4%B8%AD%E7%9A%84%E9%94%AE%E7%9B%98%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F-95ef89dd-7142-4b50-afb2-f762f663ceb2#PickTab=macOS ","date":"2024-12-16T00:00:00Z","permalink":"https://blog.kuludu.net/article/macos-ms-office-auto-number/","title":"macOS版MS Office实现自动正规形式图标编号"},{"content":"多线程同步是现代程序设计中一个重要问题，想要深入理解这一问题，就不得不深入到处理器与操作系统的具体实现中。但是我水平有限┑(￣Д ￣)┍，本文不过于详细地去探讨这一问题，而是以有锁栈与无锁栈作为切入点，主要对代码实现与实验性能上对两者进行一个比较。\n有锁栈与无锁栈 有锁栈的实现方式其实比较简单，在线程进入临界区的时候加锁即可，在完成对栈的操作解除对锁的占有。但是加锁解锁的过程对资源的消耗比较大，当线程没有Acquire到锁的时候会发生状态的切换，这在需要高性能计算的场景下或许并不合适。\nCompare And Swap(CAS)是一种常见的原子操作，是实现无锁同步的一个方式，其主要思想就是Compare和Swap两个过程。Compare的目的主要是探测内存中的值是否为期待值，如果是则Swap为设定的值。这主要依赖于处理器的实现，比如x86处理器的CMPXCHG与ARM处理器的LDREX/STREX。\n实现与实验 C++实现 本文主要对比C++标准库实现的栈，会用到一些比较新的C++标准，实验环境为：\n腾讯云Cloud Studio 1C2G（致谢！） gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.2) g++ experiment.cpp -o experiment -pthread 为了减少代码冗余，两个栈实现的内部数据结构均为以下代码段。\n1 2 3 4 5 6 template\u0026lt;typename T\u0026gt; struct Node { T data; Node* next; Node(const T\u0026amp; data) : data(data), next(nullptr) {} }; 以下为有锁栈的实现代码的核心部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void push(const T\u0026amp; data) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); Node\u0026lt;T\u0026gt;* new_node = new Node\u0026lt;T\u0026gt;(data); new_node-\u0026gt;next = head; head = new_node; } T top() const { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); Node\u0026lt;T\u0026gt;* top_node = head; if (top_node) { return top_node-\u0026gt;data; } throw std::runtime_error(\u0026#34;Stack is empty.\u0026#34;); } void pop() { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); Node\u0026lt;T\u0026gt;* top_node = head; if (top_node) { Node\u0026lt;T\u0026gt;* next_node = top_node-\u0026gt;next; head = next_node; delete top_node; return; } throw std::runtime_error(\u0026#34;Stack is empty.\u0026#34;); } bool is_empty() const noexcept { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); return head == nullptr; } 有锁栈的实现主要依赖互斥锁（mutex \u0026amp; unique_lock）实现，线程在进行每项操作时需要先Acquire锁的所有权，在执行完操作后需要Release锁的所有权。在这里我们不对修改操作的合法性进行检查，而是选择直接对不合法的越界操作抛出异常。有锁栈的实现简单，符合一般的多线程编程逻辑比较直观。在这里使用标准库自带的RAII锁，编程实现非常简单。\n以下为无锁栈实现的核心部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 std::atomic\u0026lt;Node\u0026lt;T\u0026gt;*\u0026gt; head; void push(const T\u0026amp; data) { Node\u0026lt;T\u0026gt;* new_node = new Node\u0026lt;T\u0026gt;(data); new_node-\u0026gt;next = head.load(std::memory_order_relaxed); while (!head.compare_exchange_weak(new_node-\u0026gt;next, new_node, std::memory_order_release, std::memory_order_relaxed)); } T top() const { Node\u0026lt;T\u0026gt;* top_node = head.load(std::memory_order_acquire); if (top_node) { return top_node-\u0026gt;data; } throw std::runtime_error(\u0026#34;Stack is empty.\u0026#34;); } void pop() { Node\u0026lt;T\u0026gt;* top_node = head.load(std::memory_order_relaxed); while (top_node) { Node\u0026lt;T\u0026gt;* next_node = top_node-\u0026gt;next; if (head.compare_exchange_weak(top_node, next_node, std::memory_order_release, std::memory_order_relaxed)) { delete top_node; return; } } throw std::runtime_error(\u0026#34;Stack is empty.\u0026#34;); } bool is_empty() const noexcept { return head.load(std::memory_order_acquire) == nullptr; } 对比有锁栈，无锁栈在实现上困难了不少，这主要牵涉到对CAS的理解上。这一部分的理论部分在前文与参考资料中有比较详细的描述，这里再简单对C++代码实现方面做一个解释：\nhead作为栈顶元素的指针，在这里使用的是原子变量类型，这主要是为了能够在一个CPU Instruction中完成对变量的操作，从而避免中间状态的产生，也就保证了操作的原子性。原子操作存在内存序的概念，在这里用到了三种内存序，分别解释如下 memory_order_relaxed: 松散内存顺序。这个模式保证了读操作不会被重排，但对于写操作没有任何保证。 memory_order_release：释放内存顺序。保障了读写顺序，通常不适用于load()。 memory_order_acquire：获取内存顺序。保障了读写顺序。 atomic.load()的作用是安全地读取一个原子变量，其中参数为内存序（Memory Order）。在Push和Pop操作中选择的load的内存序为memory_order_relaxed，这是因为这里考虑CAS方式乱序地插入与删除元素，即元素本身的顺序并不重要；而在IsEmpty操作中的内存序为memory_order_acquire，这主要是考虑在当前时间点执行IsEmpty的结果的正确性。 atomic.compare_exchange_weak()用于执行原子比较和交换操作，也就是CAS机制的主要实现。其中一个参数为Expected，是Compare过程比较的值；第二个变量为Desire，是Swap过程想要交换为的值。其工作过程为，比较atomic变量与Expected是否相等，如果相等则交换为Desire，否则退化为一个load的过程，将最新的atomic的值加载进Desire。后两个参数则为比较success或failure后的内存序。值得一提的是atomic.compare_exchange_strong()也值得了解，其主要适用于不需要循环重试的场景，关注可靠性的场景。 这一部分的内容有一些难理解，如果读到这里你有所困惑，建议去查找更多关于CAS机制及C++内存序的相关资料，本文不再详细展开（没错我也讲不明白😔）。\n为了进行公平对比，在这里定义实验任务为：在每个线程中执行1,000,000次入栈操作，如下。\n1 2 3 4 5 6 auto ok = pool.enqueue([\u0026amp;] { for (int i = 0; i \u0026lt; 1000000; ++i) stack.push(i); return true; }); 在这里我使用线程池创建了两个线程，从任务创建开始计时，以两个线程的入栈任务结束截止计时，核心代码如下所示。\n1 2 3 4 5 6 7 8 9 auto start = std::chrono::high_resolution_clock::now(); // Assign tasks to thread pool. if (ok_1.get() \u0026amp;\u0026amp; ok_2.get()) { auto stop = std::chrono::high_resolution_clock::now(); auto duration = std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(stop - start); std::cout \u0026lt;\u0026lt; duration.count() \u0026lt;\u0026lt; std::endl; } 本文所提到的线程池、有锁栈和无锁栈的完整代码实现均可在本人的开源项目MyDSA中找到（如果对你有用，也麻烦点一个小星星呀！）。\n实验结果 实验结果如下表（单位为microsecond）。\n方法 有锁栈 无锁栈 #1 1,003,863 399,217 #2 884,579 186,314 #3 1,013,956 427,235 Avg 967,466 337,588 从实验结果的平均值来看，有锁栈相较于无锁栈快了2.86倍。当然这只是从入栈效率上来进行比较的，如果加上随机出栈与取值操作可能会有差异。\nReference 基本功 | 一文讲清多线程和多线程同步 C++无锁编程——无锁栈(lock-free stack) C++六种内存序详解 ","date":"2024-10-25T09:35:00+08:00","permalink":"https://blog.kuludu.net/article/lock-required-stack-vs-lock-free-stack/","title":"有锁栈与无锁栈，实现与性能对比"},{"content":"突然换了一个新的博客发布方式。\n其实主要原因还是原来的博客服务器现在已经运行太多的服务从而不堪重负，apache时不时被OOM Kill导致博客也时不时跟着崩溃。\n加之原博客个人感觉更像一个笔记本，其记录的草稿一般的内容一直是我想改进的（虽然我的写作能力仍然不行）。\n所以，不如做一个fresh start，从一个新博客重新开始。\n新的博客是一个静态博客，采用hugo作为生成器。然而目前我对这个新玩意还很不熟悉，估计也需要很长一段时间才能适应吧～\n当然，原来的博客上仍然有不少有价值的文章，我会在后续的review过程中迁移过来，同时也希望能够改进文章质量，老博客已经迁移到了https://old-blog.kuludu.net/。\nAnyway, that is a new start.\n","date":"2024-06-15T19:45:00+08:00","permalink":"https://blog.kuludu.net/article/hello-new-blog/","title":"你好！新博客"},{"content":"目前我们的实验室有两条线路：\n172.C.D.0/24: 校园网（不可连接互联网，但可以接入VPN） 192.168.B.0/24: 实验室宽带网（可以连接互联网，但是没有公网IP） 我们的主要需求是通过校园网实现远程SSH接入，通过实验室宽带网访问互联网。但是由于Ubuntu生成的默认网关会自动将所有流量转到metric小的接口上，这将导致原本应该从校园网出口流出的SSH流量也走了实验室宽带网，从而无法建立SSH连接。这就需要对路由进行修改，可以通过netplan工具进行。\n由于校园网的路由已经建立且正确，所以在默认网络配置下的主要问题其实是主机内路由表能否正确找到到客户端的路由路径，而且由于VPN的存在，还需要考虑其产生的虚拟IP到主机的路由。\n编辑/etc/netplan/50-cloud-init.yaml（这是Ubuntu 24.04默认的网络配置文件，也有可能会变动），将路由项写入：\n1 2 3 4 5 6 7 8 9 10 11 12 network: ethernets: eno1: addresses: - 172.C.D.E/24 # 主机校园网IP routes: - to: 172.A.0.0/12 # 整个校园网的子网 via: 172.C.D.1 # 当前网关（下同） - to: 211.64.0.0/13 # VPN的虚拟IP子网 via: 172.C.D.1 eno2: dhcp4: true # 实验室宽带网（直接使用DHCP配置） 接下来使用netplan apply进行应用，就可以实现两条线路分工工作了。\n当然，实现上述目标还有其它方法（例如通过设置路由表使流量强制走来时的接口），但是这些做法稍显复杂，就不在此赘述了。\n","date":"2024-05-20T00:00:00Z","permalink":"https://blog.kuludu.net/article/%E5%A4%9A%E7%BD%91%E5%8F%A3%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%85%8D%E7%BD%AEubuntu%E7%BD%91%E7%BB%9C%E8%B7%AF%E7%94%B1/","title":"多网口环境下配置Ubuntu网络路由"},{"content":"好久没有更新博客了，趁着迁移服务器的劲头顺便记录一下。\n为什么要迁移？ 其实目前这台博客服务器上同时运行着多个服务：\nTypecho（也就是本博客） kodbox网盘 HackJNDoor（https://github.com/Kuludu/HackJNDoor） frp（几乎不使用） 然而，源站是我三年前在腾讯云的某个活动购买的LightHouse主机（三年期），只有6M的出口带宽实在是满足不了平时网盘的日常使用（这个情况随着数据的增加愈发显著🤷），再加之主机即将过期，所以就有了迁移的念头。\n往哪儿迁移？ 因为有备案的原因，所以我优先考虑腾讯云（这也算是被绑定了吧）。那么基本上就只剩下了继续购买LightHouse或者转CVM两个选择。\n腾讯云的LightHouse采取的是捆绑销售的模式，2U2G的典型带宽基本围绕在4M左右，这甚至还不如我这个活动机\u0026hellip;再者我运行的服务主要是流量突发，大多数时候只需要瞬时高带宽，按照带宽计费实在是浪费。\n于是我把目光转向了CVM。\n说句老实话，我对CVM的印象还停留在好几年前，对通货膨胀后CVM的价格更是已经完全没了概念（对于穷苦研究生来说好贵呀😓）。\n但是吧，对于我这种业务量其实用星星海服务器（SA2系列）中最低配置的话，总体成本还是要低于LightHouse的，加上我对硬盘读写也完全没有要求，不用SSD又可以省一大笔。同时切换流量计费，用100M的带宽只要¥0.8/G，这对我月均用不到3个G的个人开发者就非常友好了（当然我实际上没有设置这么高，因为用不到🤷）。\n嗯，南京区最近又在搞活动，我的物理位置离南京也挺近的，就它了。\n怎样迁移？ 首先，由于CentOS即将停止维护，老主机的系统得换掉了\u0026hellip;因为科研工作的缘故我近年来用Ubuntu用的相对较多，所以这次决定加入Debian系列发行版的阵营。缺点就是无法按文件迁移，而且好多软件需要重新部署。\n不过好在我的业务并不复杂，直接打包整个网页程序就好了，就是从广州LightHouse到南京CVM没有内网（云联网要收费），用6M的小水管通过SFTP传文件很漫长。\n借着这个机会，我也对Apache的VirtualHost逻辑进行了重写，我才发现几年前写的转发策略有很大的问题🤦\u0026hellip;\u0026hellip;\n在部署网盘的时候我有留意一下后台负载，发现有时候在长时间不访问后突然使用CPU负载会飙到非常高的程度，猜测这与某些缓存策略有关。不过大部分时间整体负载都不高。从我目前的工作流来说，也不太可能出现大规模文件读写的场景，所以目前的迁移算是okay的。\n配置好一切，切换DNS平滑过渡👏。\n总结 总的来说，目前迁移的体验还是很好的，也希望未来一个多月的过渡期没有什么岔子吧。\n本文写的比较意识流，但是还是希望对和我一样近期有服务器迁移打算的个人开发者有帮助。（我这博客估计也没人看🤷）\n","date":"2023-12-20T13:13:52+08:00","permalink":"https://blog.kuludu.net/article/%E4%BB%8Elighthouse%E5%88%B0cvm/","title":"从LightHouse到CVM"},{"content":"在Google Scholar或者其它数据库向EndNote20中导入引文的时候，有时候会发现其字段不受支持。如在默认设置中，Journal Article就没有Publisher这一个字段，虽然大多数论文引用格式并不要求写出出版商，但是对于某一些缺失的字段无法被添加还是会造成一些麻烦的。本文就文献导入到引用导出全流程介绍EndNote20自定义字段设置问题。\n在设置中修改Reference Types（引用类型） 首先，我们需要在Settings \u0026gt; Reference Types中修改默认的引用类型。在这里的修改是针对某一文章类型来的，这里根据需要可以修改两个常用类型Journal Article（期刊文章）和Conference Proceedings（会议出版物）（下同）。\n以Journal Article（期刊文章）为例，可以看到，Publisher字段其实是受支持的，不过在EndNote20中被默认隐藏了。将留空的Publisher字段重新填充上去即可启用该字段。\n如果有其它自定义字段，可以使用Custom 1 ~ 8八个栏位，将需要的字段名称填入即可。\n至此，我们可以在文献选项卡中看到新的字段了。\n修改默认的Import Filters（导入过滤器） 既然EndNote20默认关闭了Publisher字段，那么导入过滤器自然也是默认忽略该字段的了，在这一步我们需要重新启用它。\n在Tools \u0026gt; Import Filters中选择Open Filter Manager，可以看到一个名为EndNote Import过滤器，这便是需要修改的对象了。\n在这里可以直接点击Edit进行修改，不过还是更推荐将默认设置复制一份后再进行操作。在macOS下Filters的路径为EndNote20安装路径下的Filters文件夹，Windows的路径逻辑应该也相同。\n将%I标签对应的{IGNORE}的标记修改为Publisher即可，其它标签的含义可以搜索参考RIS文件的格式说明，自定义字段亦是如此。\n在导入文献的时候记得要选择新修改的过滤器。对于非RIS格式的引用，则需要修改对应的Import Filter。\n修改默认的Output Styles（导出格式） 由于在我的论文写作中几乎只使用LaTeX作为排版工具，在这里我着重介绍一下Bibliography的导出。\n在Tools \u0026gt; Output Styles中选择Open Style Manager，修改BibTex Export即可，同样地也推荐备份一遍默认设置。\n选择Bibliography选项卡，将需要的字段以同样的格式添加进去即可，注意修改对应的文章类型。\n同样地，若是需要修改纯文本的导出格式，可以修改Citations选项卡下的内容，读者可以搜索相关资料。\n至此，EndNote20已经可以完美地收录和导出所需的字段了。\n","date":"2023-08-21T14:41:30+08:00","permalink":"https://blog.kuludu.net/article/%E5%85%B3%E4%BA%8E%E6%96%87%E7%8C%AE%E5%AF%BC%E5%85%A5endnote20%E5%AD%97%E6%AE%B5%E9%BB%98%E8%AE%A4%E4%B8%8D%E6%94%AF%E6%8C%81%E7%9A%84%E9%97%AE%E9%A2%98/","title":"关于文献导入EndNote20字段默认不支持的问题"},{"content":"最近的工作需要使用深度学习技术，也就免不了使用GPU，然而目前我实验室的机器上使用的是Windows 11的操作系统，用来进行实验确不符合我一个常年不用Windows系统的人的习惯😓，于是我买来一块移动硬盘并在这之上部署了基于Ubuntu 22.04 LTS的PyTorch的深度学习环境。起初我以为会一切顺利，可万万没想到重装一时爽，配环境火葬场\u0026hellip;本文谨记录在这中踩的坑。\n关于移动硬盘外挂操作系统 就目前来说，我的建议是：不要这么做，至少不要使用机械硬盘。\n我手上这块是WD Element的机械移动硬盘，简单测试了一下顺序读写速度，分别为：5.7GB/S和128MB/S。看着还不错，可一旦到了随机读写任务上速度与延迟就一言难尽了。直观的感受就是一个字——卡，但是主要体现在读盘冷启动的时候（毕竟实验室机器的配置还是不错的）。\n关于NVIDIA驱动问题 说句实话，我之前从未在Linux上配置过深度学习环境，用的往往是配置好了的现成品，这一次我多多少少理解为什么大家都在说Linux上的NVIDIA驱动很难用了\u0026hellip;事实上为了处理驱动问题，我从下午13时一直干到了下午17时（其实主要受磁盘IO速度与实验室网络环境影响）。\n在安装Ubuntu系统的时候，安装程序有询问是否要安装附加驱动（Additional Drivers），我自然是勾选了确定。进入系统，在miniconda虚环境下安装PyTorch，始终无法安装对应GPU版本（CUDA）。检查发现自动安装的驱动并不是最新的（应该是510版本），本能地以为升级驱动就可以了，没想到这只是噩梦的开始。\n事实上，安装驱动的方法并不只有一种，至少我找到的方法就有三种：\n从NVIDIA官网下载。 使用ubuntu-drivers autoinstall安装。 使用系统应用Additional Drivers安装。（事实证明，这是最好的方法） 试试安装从NVIDIA官网下载的驱动 其实早在安装系统前，我已经提前在NVIDIA官网下好了对应的驱动程序，但是执行后发现至少有两个问题：\n安装驱动程序需要停止一切占用GPU的进程，其中就包含Ubuntu自带的桌面环境GNOME。这一点可以通过使用Nouveau驱动解决。 驱动安装程序提示建议使用Ubuntu发行版渠道下载驱动，因官网驱动并不是最兼容最优化版本。 那就用ubuntu-drivers autoinstall安装驱动吧 按理来说，从这里安装应该是稳妥的，但是不知道是否是因为bug的原因，安装的驱动一直报错。最后无奈只能使用apt purge清除掉所有的相关软件包了。\n最后还是使用系统应用Additional Drivers安装驱动吧 最开始其实我也是从这里安装的驱动，然而受到了一篇教程的蛊惑，最后放弃了这一步。回过头来才发觉，当初就应该使用这一方法。当然这之中也遇到了一个问题，那就是开源驱动(open kernel)驱动的问题——一开始我使用的是525版本的开源驱动，事实上这也是上一步中ubuntu-drivers推荐我安装的。然而在两次清洁安装后，显示的错误是一致的，均是无法找到设备。随后我开始怀疑是不是开源驱动的问题，遂安装525版本的非开源版本，问题解决。\n驱动问题解决了，使用conda install，成功一键部署PyTorch的GPU版本。\n关于XRDP远程桌面 由于实验室网络登录方式是Web Portal，所以有一个图形化界面还是更加方便一些。在按照教程配置好后，连接的结果却是黑屏和闪退。按照我搜索到的资料，大多数的资料指向向/etc/xrdp/startwm.sh中添加以下字段:\n1 2 unset DBUS_SESSION_BUS_ADDRESS unset XDG_RUNTIME_DIR 实际上，完全配置XRDP还需要向xsessionrc中添加桌面程序（比如Ubuntu自带的GNOME）。而我最后的解决方案还是通过查看XRDP的错误日志，安装dbus-lauch这一缺失的软件包解决的。\n总结：\n不要使用移动硬盘安装操作系统，至少不要使用机械硬盘。 尽量参考外文官网资料，因其往往更新更详尽。 检查程序日志而不是搜索症状。 ","date":"2023-02-20T12:48:10+08:00","permalink":"https://blog.kuludu.net/article/%E8%AE%B0%E5%9C%A8ubuntu-22-04-lts%E4%B8%8A%E9%83%A8%E7%BD%B2pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/","title":"记在Ubuntu 22.04 LTS上部署PyTorch深度学习环境"},{"content":"关于non-IID数据 independent and identically distributed(IID)即独立同分布，指的是全体样本服从某一分布，而每次获得的样本都是独立地从这个分布上采样获得的。\n独立：指的是每次采样之间不会有关系。例如多次投骰子，第一次投和第十次投之间没有什么关系；相较之下，出现乌云与下雨就非独立。\n同分布：指的是随机变量服从统一分布。仍以骰子举例，若骰子质量分布不会变动，则每次投的结果将会呈现一定的规律；相较之下若采用作弊骰子（可以人为改变某一端的质量），则会破坏这一性质。\nnon-IID自然是以上概念的否命题（独立和同分布任意不满足即可）。\n联邦学习中的non-IID数据分类 在真实世界中数据往往会因为各种各样的原因而呈现non-IID的特性（例如某地雨水天气多，生锈故障的样本会更多）。在机器学习领域，我们不妨从输入空间$X$与输出空间$Y$来考虑。\n假设样本独立但不同分布 样本满足贝叶斯公式：$P(X,Y)=P(X)P(Y|X)$。对于客户端$i$与$j$，考虑$P_i(X)$（$i$输入分布）、$P_i(Y|X)$（$i$标签分布）与$P_j(X)$（$j$输入分布）、$P_j(Y|X)$（$j$输入分布）。\n若$P_i(X)\\ne P_j(X)$，且$P_i(Y|X)=P_j(Y|X)$：客户端输入不相同，但输出相同。例如不同国家对于汽车行驶方向的规定不同，但都需要遵守相同的交通规则（跟随信号灯）。 若$P_i(X)= P_j(X)$，且$P_i(Y|X)\\ne P_j(Y|X)$：客户端输入相同，但输出不相同。例如不同地区对于交通法规的定义不同，有些地区红灯必须停止，而有些地区可以在确认安全的情况下通行。 若$P_i(X)\\ne P_j(X)$，且$P_i(Y|X)\\ne P_j(Y|X)$：客户端输入输出均不相同。此为以上两种情况的组合，例如行驶方向与交通法规均不相同。 若$P_i(X)=P_j(X)$，且$P_i(Y|X)=P_j(Y|X)$：与假设不符（这是IID）。\n假设样本不独立但同分布 对于全体样本而言考虑$X\\sim B(n,p)$，那么若有$Y=(n-X)\\sim B(n,p)$则输入与输出不独立但同分布。例如抛$n$次硬币$x$次正面朝上的概率与$n-x$次反面朝上的概率。\n放在联邦学习的角度，可以理解为$P_i(X)$与$P_j(X)$不独立，而$P_i(Y|X)=P_j(Y|X)$服从同一分布。例如银行中用户数据异构但用户大多一样。\n假设样本不独立且不同分布 比如读paper与掉头发的关系（？\n再从样本特性上分类 属性倾斜 属性倾斜从客户端样本属性重叠程度出发考虑，分为：非重叠属性倾斜（Non-overlapping Attribute Skew）、部分重叠属性倾斜（Partial Overlapping Attribute Skew）与完全重叠属性倾斜（Full Overlapping Attribute Skew）。\n非重叠属性倾斜 客户端的属性完全没有重叠（例如$k_1$拥有属性$A,B$，$k_2$拥有属性$C,D$），但展现强相关性，此时可以视为纵向联邦学习（Vertical FL）。\n部分重叠属性倾斜 客户端的属性部分重叠（例如$k_1$拥有属性$A,B$，$k_2$拥有属性$B,D$）。\n完全重叠属性倾斜 客户端的属性部分重叠（例如$k_1$拥有属性$A,B$，$k_2$也拥有属性$A,B$）。\n标签倾斜 标签分布倾斜 标签偏好倾斜 客户端对样本的偏好不同（对于同一样本，客户端$A$喜欢，$B$不喜欢）。\n时间倾斜 随着时间的推移，客户端的数据会有所倾斜（可参考联邦增量学习）。\n其它 属性\u0026amp;标签倾斜 质量倾斜 Ref Non-IID data and Continual Learning processes in Federated Learning: A long road ahead Federated Learning on Non-IID Data: A Survey Federated Visual Classification with Real-World Data Distribution 《机器学习》 - 周志华著 ","date":"2022-09-23T14:07:00+08:00","permalink":"https://blog.kuludu.net/article/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84non-iid%E6%95%B0%E6%8D%AE/","title":"联邦学习中的non-IID数据"},{"content":"前一阵，后辈问了我一个问题：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main() { vector\u0026lt;int\u0026gt; a = {1, 2, 3, 4, 5, 6}; auto p = lower_bound(a.begin(), a.end(), 3, greater\u0026lt;int\u0026gt;()); cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; return 0; } 为什么这段代码为什么执行结果为0？\n确实，从直观思考上来说，返回结果确实有些诡异。一时间我也不太理解。\n我的第一反应是比较 p与 a.end()的位置关系，发现 p=a.end()。也就是说，函数并没有在容器中找到比a大的元素，这并不符合预期的执行结果。\n遇事不决翻文档，于是我找到了这篇文章。其中详细介绍了 upper_bound函数的原型与定义，其中介绍中的这句话解决了这个问题：\n范围 [first, last) 必须已相对于表达式 !(value \u0026lt; element) 或 !comp(value, element) 划分，即所有令此表达式为 true 的元素必须前趋所有令此表达式为 false 的元素。完全排序的范围满足此判别标准。\n除了常提到的序列有序前提以外，lower_bound对重载的比较关系也有一定的要求，这也就导致了上例中 lower_bound函数不符合预期的执行。\n参考其给出了函数可能的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 template\u0026lt;class ForwardIt, class T, class Compare\u0026gt; ForwardIt upper_bound(ForwardIt first, ForwardIt last, const T\u0026amp; value, Compare comp) { ForwardIt it; typename std::iterator_traits\u0026lt;ForwardIt\u0026gt;::difference_type count, step; count = std::distance(first,last); while (count \u0026gt; 0) { it = first; step = count / 2; std::advance(it, step); if (!comp(value, *it)) { first = ++it; count -= step + 1; } else count = step; } return first; } 也对应了介绍中的说法，当采用上例的函数模版重载大小关系，会使迭代器 it不断向后迭代，直至与 a.end()重合。\n所以，要使运行结果正确，可以对函数传递 a的反向迭代器 a.rbegin()与 a.rend()。即：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main() { vector\u0026lt;int\u0026gt; a = {1, 2, 3, 4, 5, 6}; auto p = lower_bound(a.rbegin(), a.rend(), 3, greater\u0026lt;int\u0026gt;()); cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; return 0; } 或者使用 reverse函数先对序列进行反转，当然，这样会造成性能损失。\n","date":"2021-06-15T15:36:00+08:00","permalink":"https://blog.kuludu.net/article/lower_bound%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9C%AA%E9%A2%84%E6%9C%9F%E7%9A%84%E6%89%A7%E8%A1%8C%E8%A1%8C%E4%B8%BA/","title":"lower_bound()的一个未预期的执行行为"},{"content":"System Extensions是macOS的一套系统拓展机制，从macOS Catalina开始出现，具体可以参考Apple Developer的这篇介绍。\n一般情况下，用户并不需要手动维护系统拓展。在拓展安装与应用卸载的过程中系统会自动检查并执行相关操作。\n然而，既然有了本文就说明有那么一个问题。\nWhat if an application fail to uninstall its own system extension?\n这个问题发生在我正想卸载我的安全软件Avast Security上。\n在执行卸载操作的时候，程序提示fail to uninstall。\n首先列出我的软件信息：macOS Big Sur 11.3.1、Avast Security（发文前最新版本）。\n系统洁癖症如我，自然不指望厂商修复了，还是手动卸载吧。\n搜索相关资料，得知macOS可以通过systemextensionsctl这个命令管理系统拓展。\n于是系统提示如下：\n1 2 3 At this time, this tool cannot be used if System Integrity Protection is enabled. This limitation will be removed in the near future. Please remember to re-enable System Integrity Protection! 没错，就是不能卸载！\n原因就是系统集成保护（SIP）的锅。有了这个机制甚至root用户也不能修改与系统及系统拓展相关的文件（也就是说root用户也没法手动关闭系统拓展）。\n坑啊！\n解决方案其实也很明了，使用command + R进入System Recovery模式，通过csrutil命令关闭这令人又爱又恨的SIP，再正常启动卸载系统拓展就行（执行过程中有种裸奔的感觉😓）。\n卸载完成后别忘了用同样的方法开启SIP！\n卸载完成后别忘了用同样的方法开启SIP！\n卸载完成后别忘了用同样的方法开启SIP！\n重要的事情说三遍，毕竟SIP还是一个非常优秀的系统保护机制的。\n（希望Apple有关解除限制的承诺能尽快兑现。\n","date":"2021-05-29T15:29:00+08:00","permalink":"https://blog.kuludu.net/article/macos%E4%B8%8B%E5%8D%B8%E8%BD%BDsystem-extensions/","title":"MacOS下卸载System Extensions"},{"content":"OG（Histogram of Oriented Gridients）即方向梯度直方图，是一种图像特征提取的方法。其最早由法国研究员Dalal等人在CVPR-2005上提出，通过图像局部梯度方向的分布描述图像中的物体边缘。\n算法主要分为以下几个步骤：\n预处理 计算梯度 计算梯度方向直方图 重叠直方图归一化 获取HOG特征向量 预处理 在这一步中，可以对图像进行裁剪与缩放以及调整图像亮度，以便后续对图像处理。\n例如：\n幂次变换 对数变换 计算梯度 通过Sobel算子计算水平与竖直梯度，并计算合梯度的幅值与方向：\n$$ g=\\sqrt{g^2_{x}+g^2_{y}} $$\n$$ \\theta=\\arctan\\frac{g_y}{g_x} $$\n因为梯度方向取绝对值，所以$\\theta\\in[0, \\pi]$，方向相反的两个梯度会被认为是同一个。\n计算梯度方向直方图 将图像划分为$n\\times m$的cell，对每个cell计算方向梯度强度直方图。在这一步中，我们需要对梯度方向进行离散化，例如可以将数据分为9个深度为20的箱，从而形成一个长度为9向量。\n重叠直方图归一化 将$x\\times x$的cell划分为一个block，采用滑动窗口的策略，对block内每一个cell拼接而成的向量进行归一化操作。\n获取HOG特征向量 在上一步中，对于每一个block，我们都得到了一个长度为$bin_{depth}\\times x^2$的向量，共计$(n-1)\\times(m-1)$个。将这些向量拼接起来，就得到了我们需要求的HOG特征向量\n参考：\nhttps://zhuanlan.zhihu.com/p/85829145 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 import cv2 import os import numpy as np from skimage import io import matplotlib.pyplot as plt from skimage.feature import hog from sklearn.svm import SVC from sklearn.metrics import precision_score,recall_score TRAIN_COUNT = 500 TEST_COUNT = 100 def get_features(object_detect, count, test=False): if test: img_path = f\u0026#34;data/test_set/{object_detect}s/{object_detect}.%d.jpg\u0026#34; start = 4001 else: img_path = f\u0026#34;data/training_set/{object_detect}s/{object_detect}.%d.jpg\u0026#34; start = 1 if object_detect == \u0026#34;cat\u0026#34;: labels = np.array([0 for _ in range(count)]).reshape(-1, 1) else: labels = np.array([1 for _ in range(count)]).reshape(-1, 1) features = list() for i in range(start, start+count): print(img_path % i) # 读取图片 gray = cv2.imread(img_path % i, cv2.IMREAD_GRAYSCALE) # 尺寸缩放 gray = cv2.resize(gray, (128, 128)) # 中值滤波 gray = cv2.medianBlur(gray, 3) # HOG特征提取 hog_image = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(8, 8)) features.append(hog_image.flatten()) features = np.array(features) return features, labels def get_predict_img(img_path): gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # 尺寸缩放 gray = cv2.resize(gray, (128, 128)) # 中值滤波 gray = cv2.medianBlur(gray, 3) normalised_blocks, hog_image = hog(gray, orientations=9, pixels_per_cell=( 8, 8), cells_per_block=(8, 8), visualise=True) return hog_image.reshape(1, -1) cat, cat_labels = get_features(object_detect=\u0026#34;cat\u0026#34;, count=TRAIN_COUNT) dog, dog_labels = get_features(object_detect=\u0026#34;dog\u0026#34;, count=TRAIN_COUNT) img = np.vstack([cat, dog]) labels = np.vstack([cat_labels, dog_labels]) res = np.hstack([img, labels]) clf = SVC(probability=True) data = res[:, :-1] labels = res[:, -1] clf.fit(data, labels) # ----------- 预测单张图片 --------------------------------- # test_img = get_predict_img(\u0026#34;training_set/cats/cat.38.jpg\u0026#34;) # pred = clf.predict(test_img) # print(pred) # ----------- 预测单张图片 --------------------------------- test_cat, test_cat_labels = get_features(object_detect=\u0026#34;cat\u0026#34;, count=TEST_COUNT, test=True) test_dog, test_dog_labels = get_features(object_detect=\u0026#34;dog\u0026#34;, count=TEST_COUNT, test=True) test_img = np.vstack([test_cat, test_dog]) test_labels = np.vstack([test_cat_labels, test_dog_labels]) pred = clf.predict(test_img) precision = precision_score(pred,test_labels) recall = recall_score(pred,test_labels) print(\u0026#34;实际类别:\u0026#34;,test_labels.flatten()) print(\u0026#34;预测类别:\u0026#34;,pred.flatten()) print(f\u0026#34;精准率:{precision}, 召回率:{recall}\u0026#34;) ","date":"2021-04-20T17:57:00+08:00","permalink":"https://blog.kuludu.net/article/hog/","title":"HOG"},{"content":"最近正在做一个炼丹深度学习的项目，不可避免地使用到了GPU加速。其中，在使用cuDNN的时候遇到了CUDNN_STATUS_ALLOC_FAILED的问题，记录一下。\n首先给出我的系统硬件以及软件环境：\nOS: Windows Server 2019 Standard CPU: Intel Xeon W-2123 3.6GHz Memory: 64G ECC GPU: NVIDIA Quadro P4000(8G) Tensorflow: 1.13.2 Keras: 2.1.5 CUDA: 10.0 cuDNN: 7.3 具体报错信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 2021-03-22 20:39:27.884555: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED 2021-03-22 20:39:27.888005: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED Traceback (most recent call last): File \u0026#34;C:\\ProgramData\\Anaconda3\\envs\\ly\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u0026#34;, line 1334, in _do_call return fn(*args) File \u0026#34;C:\\ProgramData\\Anaconda3\\envs\\ly\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u0026#34;, line 1319, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata) File \u0026#34;C:\\ProgramData\\Anaconda3\\envs\\ly\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u0026#34;, line 1407, in _call_tf_sessionrun run_metadata) tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [[{{node conv2d_1/convolution}}]] [[{{node concat_9}}]] Quick Fix 此处参考stackoverflow上的一个方案。\n1 2 import os os.environ[\u0026#34;CUDA_VISIBLE_DEVICES\u0026#34;] = \u0026#34;-1\u0026#34; 直接禁用GPU，自然也就不会牵扯到cuDNN。\nProblem solved, amazing!\n个鬼。\n禁用GPU也就意味着禁用了GPU加速，意味着可怜的CPU要burn itself，这在对于效率有要求的生产环境是不行的🙅‍♂️。\n观察 在建立模型后显存直接爆炸，如下图：\n查阅资料，初步猜测是显存不足导致的，所以想到了限制一下显存的消耗：\n1 2 3 4 5 import tensorflow as tf from keras.backend.tensorflow_backend import set_session config = tf.ConfigProto() config.gpu_options.allow_growth = True set_session(tf.Session(config=config)) 限制后显存明显降低了。\n但是崩溃的问题依旧😓。\n又想到了一个问题，因为服务器是多个项目组共用的，是不是有可能为其它组正在使用导致cuDNN无法创建句柄呢？\n有可能，但是我也不能去关别人的程序呀boss不得打死我😅。\n疑问留在这里，等服务器空了就来补充。（当然可能我也压根不会填坑，不如留给读者当一个思路）\nReference https://github.com/tensorflow/tensorflow/issues/39989\nhttps://blog.csdn.net/qq_40635998/article/details/87297634\n","date":"2021-03-22T21:42:00+08:00","permalink":"https://blog.kuludu.net/article/%E8%A7%A3%E5%86%B3-cudnn_status_alloc_failed/","title":"“解决”CUDNN_STATUS_ALLOC_FAILED"},{"content":"在macOS 11.1下测试通过。\ngpg (GnuPG) 2.2.25 libgcrypt 1.8.7 pinentry-mac (pinentry) 0.9.4 安装所需软件 1 brew install gpg2 gnupg pinentry-mac 创建钥匙对 1 gpg --full-generate-key 这里建议使用--full-generate-key选项自定义全部选项，按照提示输入即可，加密方法选(1) RSA and RSA (default)，密钥长度可选择最长4096。\n其中邮箱地址需要与Github中验证通过的邮箱保持一致。\n设置终端环境变量 1 export GPG_TTY=$(tty) 在这一步，设置GPG终端类型环境变量，目的是让GPG程序知道使用什么作为终端，并使其生效：\n1 source ~/.zshrc # 如果使用的是bash，更改为.bashrc 配置GPG代理 1 vim ~/.gnupg/gpg-agent.conf 将以下内容追加进入配置文件\n1 pinentry-program /usr/local/bin/pinentry-mac 这样，就可以使用pinentry管理GPG密钥了。\n载入GPG代理配置 1 gpgconf --kill gpg-agent 通过杀死gpg-agent，确保配置文件被加载。\n测试一下 1 echo \u0026#34;test\u0026#34; | gpg --clearsign 运行以上命令，对字符串test进行签名以测试gpg是否配置成功。\n如果配置成功，应该会出现pinentry的窗口，选择Save in keychain可以将密码保存至钥匙链。\n正确输入密码后，可以看到信息和签名。\n获取密钥ID 1 gpg -K --keyid-format SHORT 执行成功应该会出现这样的内容：\n1 2 3 4 ------------------------------------- sec rsa4096/\u0026lt;Key ID Short\u0026gt; 2020-12-27 [SC] [expires: 2024-12-26] \u0026lt;Key ID\u0026gt; uid [ultimate] example \u0026lt;example@example.com\u0026gt; 使用Key ID Short或Key ID均可。\n在Git中设置密钥 1 git config --global user.signingkey \u0026lt;Key ID\u0026gt; 通过以上命令可以在全局设置中配置密钥ID。\n开启强制签名 通过以上步骤就可以实现GPG签名commit了，只需要添加-S选项即可，如下：\n1 git commit -S -m \u0026#34;这是一条签名过的commit\u0026#34; 但是为了方便，我们可以通过全局设置来强制开启GPG\n1 2 git config --global commit.gpgsign true git config --global tag.forceSignAnnotated true 其中第一个参数是默认开启签名，第二个参数是强制开启签名。\n后记 在最初的配置过程完成后，我对我的一个仓库进行commit操作出现错误，如下：\n1 2 error: gpg failed to sign the data fatal: failed to write commit object 通过加入GIT_TRACE=1 参数观察Git的执行过程，我发现其卡死在了这个命令的执行上：\n1 gpg --status-fd=2 -bsau \u0026lt;Key ID\u0026gt; 具体是什么原因我并未做深究。\n参考 https://help.github.com/articles/signing-commits-using-gpg/ https://gist.github.com/troyfontaine/18c9146295168ee9ca2b30c00bd1b41e https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/signing-commits https://merikan.com/2019/05/how-to-sign-git-commits/ ","date":"2020-12-27T23:41:00+08:00","permalink":"https://blog.kuludu.net/article/%E5%9C%A8macos%E4%B8%8B%E4%BD%BF%E7%94%A8gpg%E5%AF%B9git-commit%E7%AD%BE%E5%90%8D/","title":"在macOS下使用GPG对Git commit签名"}]